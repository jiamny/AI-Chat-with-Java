# AI Chat with Java

Projects show how to integrates Ollama with Apache HttpClient, Sprinh boot AI, DeepSeek and other LLM models to provide an interactive AI chat experience locally. 


## Prerequisites

Before you begin, ensure you have the following installed:

1. Java 17 or higher
2. Maven
3. Ollama
   - Install Ollama: Follow the instructions [here](https://ollama.ai/).
   - Pull the LLM models: for example, Run `ollama pull deepseek-r1:1.5b` in your terminal to load deepseek-r1:1.5b locally.
4. Spring AI
4. Git

## Project 

- **AI-chat-with-Spring-boot** application features standard API endpoints for AI responses, along with a simple, modern Web UI.
![Alt text](./AI-chat-with-Spring-boot/Screenshot.png?raw=true)


- **deepseek4j_chat_with_httpclient** application features askng questions and getting responses powered by DeepSeek AI and HttpClient.




